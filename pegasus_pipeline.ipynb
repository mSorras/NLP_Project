{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb3bb13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at tuner007/pegasus_paraphrase and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ORIGINAL TEXT 1:\n",
      "Today is our dragon boat festival, in our Chinese culture, to celebrate it with all safe and great in our lives. Hope you too, to enjoy it as my deepest wishes. Thank your message to show our words to  the doctor, as his next contract checking, to all of us. I got this message to see the approved message. In fact, I have received the message from  the professor, to show me, this, a couple of days ago.  I am very appreciated  the full support of the professor, for our Springer proceedings publication.\n",
      "\n",
      "PARAPHRASED TEXT 1:\n",
      "The dragon boat festival is celebrated in our Chinese culture and we should all be happy. Hope you enjoy it as much as I did. Thank you for your message, which will be shown to the doctor as his next contract checking. I saw the approved message after getting this message. I received the message from the professor a couple of days ago. The professor supported the Springer proceedings publication.\n",
      "====================================================================================================\n",
      "\n",
      "ORIGINAL TEXT 2:\n",
      "During our final discuss, I told him about the new submission — the one we were waiting since last autumn, but the updates was confusing as it not included the full feedback from reviewer or maybe editor? Anyway, I believe the team, although bit delay and less communication at recent days, they really tried best for paper and cooperation. We should be grateful, I mean all of us, for the acceptance and efforts until the Springer link came finally last week, I think. Also, kindly remind me please, if the doctor still plan for the acknowledgments section edit before he sending again. Because I didn’t see that part final yet, or maybe I missed, I apologize if so. Overall, let us make sure all are safe and celebrate the outcome with strong coffee and future targets.\n",
      "\n",
      "PARAPHRASED TEXT 2:\n",
      "I told him about the new submission we were waiting for, but the updates were confusing as they did not include the full feedback from the reviewer or editor. I think the team tried their best for paper and cooperation despite the recent delay and less communication. We should be thankful for the acceptance and efforts until the Springer link came last week, I think. If the doctor still plans for the acknowledgments section to be edited before he sends again, please remind me. I apologize if I missed that part final. Let's make sure all are safe and celebrate the outcome with coffee and targets.\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "from transformers import PegasusTokenizer, PegasusForConditionalGeneration\n",
    "import torch\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import nltk\n",
    "\n",
    "# Φόρτωση μοντέλου και tokenizer\n",
    "model_name = \"tuner007/pegasus_paraphrase\"\n",
    "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "model = PegasusForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# Συνάρτηση paraphrasing ανά πρόταση με sampling\n",
    "def paraphrase_sentence_sampling(sentence, max_length=256):\n",
    "    batch = tokenizer.prepare_seq2seq_batch([sentence], truncation=True, padding='longest', return_tensors=\"pt\")\n",
    "    translated = model.generate(\n",
    "        **batch,\n",
    "        do_sample=True,\n",
    "        top_k=30,\n",
    "        top_p=0.90,\n",
    "        temperature=0.9,\n",
    "        max_length=max_length,\n",
    "        num_return_sequences=1\n",
    "    )\n",
    "    return tokenizer.decode(translated[0], skip_special_tokens=True)\n",
    "\n",
    "# Paraphrasing όλων των προτάσεων ενός κειμένου (πρόταση προς πρόταση για να μη χαθεί καμία)\n",
    "def paraphrase_full_text_sampling(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    paraphrased_sentences = []\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        try:\n",
    "            paraphrased = paraphrase_sentence_sampling(sentence)\n",
    "            paraphrased_sentences.append(paraphrased)\n",
    "        except Exception as e:\n",
    "            print(f\"Sentence {i+1} failed: {e}\")\n",
    "            paraphrased_sentences.append(sentence)  # fallback\n",
    "    return \" \".join(paraphrased_sentences)\n",
    "\n",
    "text1 = \"\"\"Today is our dragon boat festival, in our Chinese culture, to celebrate it with all safe and great in our lives. Hope you too, to enjoy it as my deepest wishes. Thank your message to show our words to  the doctor, as his next contract checking, to all of us. I got this message to see the approved message. In fact, I have received the message from  the professor, to show me, this, a couple of days ago.  I am very appreciated  the full support of the professor, for our Springer proceedings publication.\"\"\"\n",
    "\n",
    "text2 = \"\"\"During our final discuss, I told him about the new submission — the one we were waiting since last autumn, but the updates was confusing as it not included the full feedback from reviewer or maybe editor? Anyway, I believe the team, although bit delay and less communication at recent days, they really tried best for paper and cooperation. We should be grateful, I mean all of us, for the acceptance and efforts until the Springer link came finally last week, I think. Also, kindly remind me please, if the doctor still plan for the acknowledgments section edit before he sending again. Because I didn’t see that part final yet, or maybe I missed, I apologize if so. Overall, let us make sure all are safe and celebrate the outcome with strong coffee and future targets.\"\"\"\n",
    "\n",
    "for i, text in enumerate([text1, text2], 1):\n",
    "    print(f\"\\nORIGINAL TEXT {i}:\\n{text}\\n\")\n",
    "    paraphrased_text = paraphrase_full_text_sampling(text)\n",
    "    print(f\"PARAPHRASED TEXT {i}:\\n{paraphrased_text}\")\n",
    "    print(\"=\"*100)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-assignment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
