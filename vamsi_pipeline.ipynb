{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9163ae45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL TEXT 1:\n",
      " Today is our dragon boat festival, in our Chinese culture, to celebrate it with all safe and great in our lives. Hope you too, to enjoy it as my deepest wishes. Thank your message to show our words to the doctor, as his next contract checking, to all of us. I got this message to see the approved message. In fact, I have received the message from the professor, to show me, this, a couple of days ago. I am very appreciated the full support of the professor, for our Springer proceedings publication.\n",
      "\n",
      "PARAPHRASED TEXT 1:\n",
      " Today is our dragon boat festival in our Chinese culture to celebrate it in our lives safe and great. I also hope that you can enjoy it as my deepest wishes. Thanks for your message to show our words to the doctor, as his next contract checking, to all of us. This message arrived to see the approved message . I have received the message from the professor to show me this a couple of days ago .  I have very greatly appreciated the professor's full support for our publication of Springer proceedings.\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "ORIGINAL TEXT 2:\n",
      " During our final discuss, I told him about the new submission — the one we were waiting since last autumn, but the updates was confusing as it not included the full feedback from reviewer or maybe editor? Anyway, I believe the team, although bit delay and less communication at recent days, they really tried best for paper and cooperation. We should be grateful, I mean all of us, for the acceptance and efforts until the Springer link came finally last week, I think. Also, kindly remind me please, if the doctor still plan for the acknowledgments section edit before he sending again. Because I didn’t see that part final yet, or maybe I missed, I apologize if so. Overall, let us make sure all are safe and celebrate the outcome with strong coffee and future targets.\n",
      "\n",
      "PARAPHRASED TEXT 2:\n",
      " During the final discussion I told him about the new submission — the one that we had waited on since last fall , but the updates were confusing as it did not include the full feedback from reviewer or maybe editor ? I believe the team actually tried better for the paper and for cooperation, although bit delay and less communication in recent days .  For the acceptance and efforts we all should be grateful, I think , until the Springer link finally came last week. Also kindly remind me if the doctor still plan for the acknowledgments section before sending it again. Because I didn’t see this part final yet, or maybe I missed it, I will apologize if so. Let us ensure that all are safe and celebrate the outcome with strong coffee and future targets .\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# Φόρτωση του μοντέλου και tokenizer\n",
    "model_name = \"Vamsi/T5_Paraphrase_Paws\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "# Συνάρτηση paraphrasing πρότασης\n",
    "def paraphrase_sentence(sentence, max_length=256):\n",
    "    input_text = f\"paraphrase: {sentence} </s>\"\n",
    "    encoding = tokenizer.encode_plus(input_text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    input_ids, attention_mask = encoding[\"input_ids\"], encoding[\"attention_mask\"]\n",
    "\n",
    "    outputs = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_length=max_length,\n",
    "        num_beams=1,\n",
    "        do_sample=True,\n",
    "        top_k=40,\n",
    "        top_p=0.92,\n",
    "        temperature=1.0,\n",
    "        num_return_sequences=1\n",
    "    )\n",
    "\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Ολόκληρο κείμενο πρόταση-πρόταση\n",
    "def paraphrase_full_text(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    paraphrased = []\n",
    "    for i, sent in enumerate(sentences):\n",
    "        try:\n",
    "            paraphrased.append(paraphrase_sentence(sent))\n",
    "        except Exception as e:\n",
    "            print(f\"Sentence {i+1} failed: {e}\")\n",
    "            paraphrased.append(sent)\n",
    "    return \" \".join(paraphrased)\n",
    "\n",
    "text1 = \"\"\"Today is our dragon boat festival, in our Chinese culture, to celebrate it with all safe and great in our lives. Hope you too, to enjoy it as my deepest wishes. Thank your message to show our words to the doctor, as his next contract checking, to all of us. I got this message to see the approved message. In fact, I have received the message from the professor, to show me, this, a couple of days ago. I am very appreciated the full support of the professor, for our Springer proceedings publication.\"\"\"\n",
    "\n",
    "text2 = \"\"\"During our final discuss, I told him about the new submission — the one we were waiting since last autumn, but the updates was confusing as it not included the full feedback from reviewer or maybe editor? Anyway, I believe the team, although bit delay and less communication at recent days, they really tried best for paper and cooperation. We should be grateful, I mean all of us, for the acceptance and efforts until the Springer link came finally last week, I think. Also, kindly remind me please, if the doctor still plan for the acknowledgments section edit before he sending again. Because I didn’t see that part final yet, or maybe I missed, I apologize if so. Overall, let us make sure all are safe and celebrate the outcome with strong coffee and future targets.\"\"\"\n",
    "\n",
    "print(\"ORIGINAL TEXT 1:\\n\", text1)\n",
    "print(\"\\nPARAPHRASED TEXT 1:\\n\", paraphrase_full_text(text1))\n",
    "print(\"\\n\" + \"=\"*100 + \"\\n\")\n",
    "print(\"ORIGINAL TEXT 2:\\n\", text2)\n",
    "print(\"\\nPARAPHRASED TEXT 2:\\n\", paraphrase_full_text(text2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-assignment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
